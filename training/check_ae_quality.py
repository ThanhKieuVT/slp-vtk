"""
Script: Check Autoencoder Reconstruction Quality (CLI Version) - SAFE MODE
"""
import torch
import numpy as np
import argparse
import os
import sys
import glob

# --- Import Modules ---
try:
    sys.path.append(os.getcwd()) 
    from models.fml.autoencoder import UnifiedPoseAutoencoder
    from data_preparation import denormalize_pose
except ImportError as e:
    print(f"âŒ Lá»—i Import: {e}")
    sys.exit(1)

def main():
    # --- 1. Cáº¤U HÃŒNH ARGPARSE ---
    parser = argparse.ArgumentParser(description='Kiá»ƒm tra cháº¥t lÆ°á»£ng Autoencoder (Stage 1)')
    
    parser.add_argument('--data_dir', type=str, required=True,
                        help='ÄÆ°á»ng dáº«n thÆ° má»¥c chá»©a normalization_stats.npz vÃ  cÃ¡c file data .npy')
    parser.add_argument('--autoencoder_checkpoint', type=str, required=True,
                        help='ÄÆ°á»ng dáº«n file checkpoint .pt cá»§a Autoencoder')
    parser.add_argument('--output_dir', type=str, default='check_stage1_output',
                        help='ThÆ° má»¥c lÆ°u file káº¿t quáº£')
    
    # ThÃªm cÃ¡c tham sá»‘ config model (Ä‘á»ƒ trÃ¡nh lá»—i náº¿u chá»‹ tá»«ng thay Ä‘á»•i khi train)
    parser.add_argument('--latent_dim', type=int, default=256)
    parser.add_argument('--hidden_dim', type=int, default=512)

    args = parser.parse_args()

    # Táº¡o thÆ° má»¥c output náº¿u chÆ°a cÃ³
    os.makedirs(args.output_dir, exist_ok=True)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸš€ Äang kiá»ƒm tra trÃªn device: {device}")

    # --- 2. TÃŒM FILE Dá»® LIá»†U Äá»‚ TEST ---
    print(f"ğŸ” Äang tÃ¬m file .npy máº«u trong: {args.data_dir}")
    npy_files = glob.glob(os.path.join(args.data_dir, "**/*.npy"), recursive=True)
    valid_files = [f for f in npy_files if 'stats' not in f and 'output' not in f and 'check' not in f]
    
    if not valid_files:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y file .npy dá»¯ liá»‡u nÃ o trong thÆ° má»¥c data_dir!")
        return
    
    sample_file = valid_files[0]
    print(f"âœ… ÄÃ£ chá»n file máº«u Ä‘á»ƒ test: {sample_file}")

    # --- 3. LOAD AUTOENCODER ---
    print(f"ğŸ“¦ Loading Autoencoder tá»«: {args.autoencoder_checkpoint}")
    
    # âš ï¸ QUAN TRá»ŒNG: Model nÃ y pháº£i khá»Ÿi táº¡o giá»‘ng há»‡t lÃºc Train
    ae = UnifiedPoseAutoencoder(
        pose_dim=214, 
        latent_dim=args.latent_dim, 
        hidden_dim=args.hidden_dim
        # Náº¿u lÃºc train chá»‹ chá»‰nh sá»‘ layers khÃ¡c máº·c Ä‘á»‹nh, pháº£i sá»­a cá»©ng á»Ÿ Ä‘Ã¢y
        # vÃ­ dá»¥: encoder_layers=4
    ).to(device)

    try:
        ckpt = torch.load(args.autoencoder_checkpoint, map_location=device)
        
        # Xá»­ lÃ½ linh hoáº¡t dictionary
        if isinstance(ckpt, dict) and 'model_state_dict' in ckpt:
            state_dict = ckpt['model_state_dict']
        else:
            state_dict = ckpt
            
        # Load strict=True Ä‘á»ƒ Ä‘áº£m báº£o khÃ´ng sai lá»‡ch layer nÃ o
        ae.load_state_dict(state_dict, strict=True)
        print("âœ… Load weights thÃ nh cÃ´ng (Strict Mode)!")
        ae.eval()
        
    except RuntimeError as e:
        print(f"âš ï¸ Lá»—i khá»›p cáº¥u trÃºc Model (Shape Mismatch): {e}")
        print("ğŸ‘‰ Gá»£i Ã½: Kiá»ƒm tra xem 'hidden_dim' hoáº·c sá»‘ layers trong code nÃ y cÃ³ khá»›p vá»›i file checkpoint khÃ´ng.")
        return
    except Exception as e:
        print(f"âŒ Lá»—i load checkpoint: {e}")
        return

    # --- 4. LOAD STATS & NORMALIZE ---
    stats_path = os.path.join(args.data_dir, "normalization_stats.npz")
    if not os.path.exists(stats_path):
        stats_path = os.path.join(args.data_dir, "../normalization_stats.npz")
        
    if not os.path.exists(stats_path):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y normalization_stats.npz! HÃ£y kiá»ƒm tra láº¡i data_dir.")
        return
        
    print("ğŸ“Š Loading Stats...")
    stats = np.load(stats_path)
    # Load lÃªn GPU Ä‘á»ƒ tÃ­nh toÃ¡n normalize
    mean = torch.tensor(stats['mean']).float().to(device)
    std = torch.tensor(stats['std']).float().to(device)

    # Äá»c file máº«u
    real_pose_np = np.load(sample_file)
    real_pose = torch.tensor(real_pose_np, dtype=torch.float32).to(device)
    
    # Normalize: (X - Mean) / Std
    # ThÃªm 1e-6 Ä‘á»ƒ trÃ¡nh chia cho 0 náº¿u std cÃ³ chá»— báº±ng 0
    real_pose_norm = (real_pose - mean) / (std + 1e-6)
    real_pose_norm = real_pose_norm.unsqueeze(0) # [1, T, 214]

    # --- 5. RECONSTRUCT ---
    print("ğŸ”„ Äang cháº¡y qua Autoencoder...")
    with torch.no_grad():
        # Mask=None vÃ¬ ta Ä‘ang test 1 file trá»n váº¹n, khÃ´ng cÃ³ padding thá»«a
        recon_norm, _ = ae(real_pose_norm)

    # --- 6. DENORMALIZE & SAVE ---
    print("ğŸ’¾ Äang lÆ°u káº¿t quáº£...")
    
    real_save_path = os.path.join(args.output_dir, "original_sample.npy")
    np.save(real_save_path, real_pose_np)
    
    recon = recon_norm.squeeze(0).cpu().numpy()
    # Denormalize báº±ng numpy array gá»‘c trong stats (hÃ m denormalize thÆ°á»ng nháº­n numpy)
    recon_final = denormalize_pose(recon, stats['mean'], stats['std'])
    
    recon_save_path = os.path.join(args.output_dir, "reconstructed_sample.npy")
    np.save(recon_save_path, recon_final)
    
    print("\nâœ… HOÃ€N Táº¤T! Káº¿t quáº£ lÆ°u táº¡i:")
    print(f"   1. Gá»‘c: {real_save_path}")
    print(f"   2. TÃ¡i táº¡o: {recon_save_path}")
    print("\nğŸ‘‰ CHáº Y Lá»†NH VISUALIZE Äá»‚ KIá»‚M TRA:")
    print(f"python visualize_single_pose.py --npy_path {recon_save_path} --output_video check_ae_result.mp4")

if __name__ == '__main__':
    main()