import torch
import numpy as np
import argparse
import os
import sys
import glob

# --- Import Modules ---
try:
    sys.path.append(os.getcwd()) 
    from models.fml.autoencoder import UnifiedPoseAutoencoder
    # Import 2 hÃ m chuáº©n tá»« file cá»§a chá»‹
    from data_preparation import normalize_pose, denormalize_pose 
except ImportError as e:
    print(f"âŒ Lá»—i Import: {e}")
    print("ğŸ’¡ Gá»£i Ã½: Äáº·t file nÃ y á»Ÿ thÆ° má»¥c gá»‘c (cÃ¹ng cáº¥p vá»›i folder 'models' vÃ  'data_preparation.py')")
    sys.exit(1)

def main():
    parser = argparse.ArgumentParser(description='Kiá»ƒm tra cháº¥t lÆ°á»£ng Autoencoder (Stage 1)')
    parser.add_argument('--data_dir', type=str, required=True, help='ThÆ° má»¥c chá»©a normalization_stats.npz')
    parser.add_argument('--autoencoder_checkpoint', type=str, required=True, help='ÄÆ°á»ng dáº«n file .pt')
    parser.add_argument('--output_dir', type=str, default='check_stage1_output')
    parser.add_argument('--latent_dim', type=int, default=256)
    parser.add_argument('--hidden_dim', type=int, default=512)

    args = parser.parse_args()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    os.makedirs(args.output_dir, exist_ok=True)

    # --- 1. LOAD STATS (Theo cáº¥u trÃºc má»›i cá»§a chá»‹) ---
    stats_path = os.path.join(args.data_dir, "normalization_stats.npz")
    if not os.path.exists(stats_path):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y stats táº¡i {stats_path}")
        return
        
    print(f"ğŸ“Š Loading Grouped Stats tá»«: {stats_path}")
    # Load stats thÃ nh dictionary Ä‘á»ƒ truyá»n vÃ o hÃ m cá»§a chá»‹
    stats_npz = np.load(stats_path)
    stats = {k: stats_npz[k] for k in stats_npz.files}

    # --- 2. LOAD MODEL ---
    print(f"ğŸ“¦ Loading Autoencoder...")
    ae = UnifiedPoseAutoencoder(
        pose_dim=214, 
        latent_dim=args.latent_dim, 
        hidden_dim=args.hidden_dim
    ).to(device)

    try:
        ckpt = torch.load(args.autoencoder_checkpoint, map_location=device)
        state_dict = ckpt['model_state_dict'] if 'model_state_dict' in ckpt else ckpt
        ae.load_state_dict(state_dict, strict=True)
        ae.eval()
        print("âœ… Load weights thÃ nh cÃ´ng!")
    except Exception as e:
        print(f"âŒ Lá»—i load checkpoint: {e}")
        return

    # --- 3. LOAD DATA MáºªU ---
    # TÃ¬m file .npz (cáº¥u trÃºc chá»‹ dÃ¹ng trong data_preparation) hoáº·c .npy
    files = glob.glob(os.path.join(args.data_dir, "**/*.npz"), recursive=True) + \
            glob.glob(os.path.join(args.data_dir, "**/*.npy"), recursive=True)
    
    valid_files = [f for f in files if "stats" not in f and "output" not in f]
    
    if not valid_files:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u máº«u!")
        return

    sample_file = valid_files[0]
    print(f"âœ… Chá»n file máº«u: {sample_file}")
    
    data = np.load(sample_file)
    # Náº¿u lÃ  file .npz cá»§a chá»‹, láº¥y key 'keypoints', náº¿u lÃ  .npy thÃ¬ láº¥y trá»±c tiáº¿p
    real_pose_np = data['keypoints'] if sample_file.endswith('.npz') and 'keypoints' in data else data
    
    # Náº¿u pose Ä‘ang lÃ  [T, 75, 2], cáº§n flatten vá» [T, 150] rá»“i ná»‘i vá»›i NMM náº¿u cáº§n
    # LÆ°u Ã½: á» Ä‘Ã¢y script giáº£ Ä‘á»‹nh file máº«u Ä‘Ã£ lÃ  214D. 
    # Náº¿u file máº«u chá»‰ lÃ  150D, chá»‹ cáº§n dÃ¹ng hÃ m load_sample trong data_preparation.py cá»§a chá»‹.
    if real_pose_np.shape[-1] != 214:
        print(f"âš ï¸ Cáº£nh bÃ¡o: File máº«u cÃ³ shape {real_pose_np.shape}, khÃ´ng pháº£i 214D.")
        print("ğŸ’¡ Script sáº½ cá»‘ gáº¯ng cháº¡y náº¿u báº¡n Ä‘Ã£ xá»­ lÃ½ concat trÆ°á»›c Ä‘Ã³.")

    # --- 4. CHUáº¨N HÃ“A & INFERENCE ---
    # Sá»­ dá»¥ng hÃ m normalize cá»§a chá»‹ (Há»— trá»£ cáº£ numpy/torch)
    real_pose_norm = normalize_pose(real_pose_np, stats)
    real_pose_tensor = torch.tensor(real_pose_norm, dtype=torch.float32).to(device).unsqueeze(0)

    print("ğŸ”„ Äang tÃ¡i táº¡o qua Autoencoder...")
    with torch.no_grad():
        recon_tensor, _ = ae(real_pose_tensor)

    # --- 5. GIáº¢I CHUáº¨N HÃ“A & LÆ¯U ---
    recon_norm_np = recon_tensor.squeeze(0).cpu().numpy()
    
    # Sá»­ dá»¥ng hÃ m denormalize cá»§a chá»‹
    recon_final = denormalize_pose(recon_norm_np, stats)
    
    # TÃ­nh lá»—i MSE Ä‘Æ¡n giáº£n Ä‘á»ƒ check nhanh
    mse = np.mean((real_pose_np - recon_final)**2)
    print(f"ğŸ“‰ Reconstruction MSE: {mse:.6f}")

    # LÆ°u káº¿t quáº£
    original_path = os.path.join(args.output_dir, "original.npy")
    recon_path = os.path.join(args.output_dir, "reconstructed.npy")
    
    np.save(original_path, real_pose_np)
    np.save(recon_path, recon_final)
    
    print(f"\nâœ… ÄÃ£ lÆ°u file gá»‘c táº¡i: {original_path}")
    print(f"âœ… ÄÃ£ lÆ°u file tÃ¡i táº¡o táº¡i: {recon_path}")
    print(f"\nğŸ‘‰ Chá»‹ cháº¡y lá»‡nh visualize Ä‘á»ƒ xem káº¿t quáº£: \npython training/visualize_single_pose.py --npy_path {recon_path}")

if __name__ == '__main__':
    main()