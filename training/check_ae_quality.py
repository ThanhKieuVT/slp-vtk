import torch
import numpy as np
import argparse
import os
import sys
import glob

# --- Import Modules (Xá»­ lÃ½ Ä‘Æ°á»ng dáº«n Colab) ---
try:
    sys.path.append(os.getcwd()) 
    from models.fml.autoencoder import UnifiedPoseAutoencoder
    # Import hÃ m chuáº©n tá»« data_preparation cá»§a chá»‹
    from data_preparation import denormalize_pose, load_sample 
except ImportError as e:
    print(f"âŒ Lá»—i Import: {e}")
    print("ğŸ’¡ Gá»£i Ã½: Chá»‹ nhá»› Ä‘áº·t file nÃ y á»Ÿ thÆ° má»¥c gá»‘c (cÃ¹ng cáº¥p vá»›i folder 'models' vÃ  file 'data_preparation.py')")
    sys.exit(1)

def main():
    # --- 1. Cáº¤U HÃŒNH THAM Sá» ---
    parser = argparse.ArgumentParser(description='Kiá»ƒm tra cháº¥t lÆ°á»£ng Autoencoder (Stage 1) - Grouped Version')
    
    parser.add_argument('--data_dir', type=str, required=True,
                        help='Folder chá»©a file normalization_stats.npz vÃ  cÃ¡c folder poses/nmms')
    parser.add_argument('--autoencoder_checkpoint', type=str, required=True,
                        help='ÄÆ°á»ng dáº«n file .pt cá»§a Autoencoder')
    parser.add_argument('--output_dir', type=str, default='check_stage1_output',
                        help='NÆ¡i lÆ°u file káº¿t quáº£')
    
    parser.add_argument('--latent_dim', type=int, default=256)
    parser.add_argument('--hidden_dim', type=int, default=512)
    parser.add_argument('--pose_dim', type=int, default=214)

    args = parser.parse_args()
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸš€ Äang kiá»ƒm tra trÃªn device: {device}")
    os.makedirs(args.output_dir, exist_ok=True)

    # --- 2. LOAD MODEL ---
    print(f"ğŸ“¦ Loading Autoencoder (pose_dim={args.pose_dim})...")
    ae = UnifiedPoseAutoencoder(
        pose_dim=args.pose_dim, 
        latent_dim=args.latent_dim, 
        hidden_dim=args.hidden_dim
    ).to(device)

    try:
        ckpt = torch.load(args.autoencoder_checkpoint, map_location=device)
        state_dict = ckpt['model_state_dict'] if 'model_state_dict' in ckpt else ckpt
        ae.load_state_dict(state_dict, strict=True)
        print("âœ… Load weights thÃ nh cÃ´ng!")
        ae.eval()
    except Exception as e:
        print(f"âŒ Lá»—i load checkpoint: {e}")
        return

    # --- 3. LOAD & PREPARE GROUPED STATS ---
    stats_path = os.path.join(args.data_dir, "normalization_stats.npz")
    if not os.path.exists(stats_path):
        # Thá»­ tÃ¬m á»Ÿ thÆ° má»¥c cha náº¿u data_dir trá» vÃ o subfolder train/test
        stats_path = os.path.join(os.path.dirname(args.data_dir), "normalization_stats.npz")
    
    if not os.path.exists(stats_path):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y normalization_stats.npz táº¡i {stats_path}")
        return
        
    print(f"ğŸ“Š Loading Grouped Stats tá»«: {stats_path}")
    stats_raw = np.load(stats_path)
    
    # Chuyá»ƒn Ä‘á»•i format sang dict Ä‘á»ƒ dÃ¹ng cho hÃ m denormalize_pose cá»§a chá»‹
    stats_dict = {
        'manual_mean': float(stats_raw['manual_mean']),
        'manual_std': float(stats_raw['manual_std']),
        'nmm_mean': stats_raw['nmm_mean'],
        'nmm_std': stats_raw['nmm_std']
    }

    # Táº¡o tensor Full 214D Ä‘á»ƒ Normalize Ä‘áº§u vÃ o
    m_mean = np.full(150, stats_dict['manual_mean'])
    m_std = np.full(150, stats_dict['manual_std'])
    full_mean = torch.tensor(np.concatenate([m_mean, stats_dict['nmm_mean']])).float().to(device)
    full_std = torch.tensor(np.concatenate([m_std, stats_dict['nmm_std']])).float().to(device)

    # --- 4. TÃŒM & LOAD FILE DATA MáºªU ---
    # QuÃ©t trong folder poses Ä‘á»ƒ láº¥y video_id
    poses_dir = os.path.join(args.data_dir, "poses")
    if not os.path.exists(poses_dir):
        poses_dir = args.data_dir # Fallback
        
    npy_files = glob.glob(os.path.join(poses_dir, "*.npz"))
    if not npy_files:
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file .npz nÃ o trong {poses_dir}")
        return

    sample_id = os.path.basename(npy_files[0]).replace('.npz', '')
    print(f"ğŸ” Äang test vá»›i Video ID: {sample_id}")
    
    # DÃ¹ng hÃ m load_sample chuáº©n cá»§a chá»‹ Ä‘á»ƒ láº¥y Ä‘á»§ 214D
    real_pose_np, T = load_sample(sample_id, args.data_dir)
    
    if real_pose_np is None:
        print("âŒ Lá»—i load_sample. Vui lÃ²ng check Ä‘Æ°á»ng dáº«n data_dir!")
        return

    real_pose_np = np.nan_to_num(real_pose_np)

    # --- 5. NORMALIZE & INFERENCE ---
    real_pose = torch.tensor(real_pose_np, dtype=torch.float32).to(device)
    # Normalize: (X - Mean) / Std
    real_pose_norm = (real_pose - full_mean) / (full_std + 1e-8)
    real_pose_input = real_pose_norm.unsqueeze(0)

    print("ğŸ”„ Äang cháº¡y qua Autoencoder...")
    with torch.no_grad():
        recon_norm, _ = ae(real_pose_input)

    # --- 6. DENORMALIZE & EVALUATE ---
    recon_np = recon_norm.squeeze(0).cpu().numpy()
    # DÃ¹ng hÃ m cá»§a chá»‹ Ä‘á»ƒ giáº£i chuáº©n hÃ³a theo nhÃ³m
    recon_final = denormalize_pose(recon_np, stats_dict) 

    # TÃ­nh MSE trÃªn giÃ¡ trá»‹ gá»‘c
    mse = np.mean((real_pose_np - recon_final)**2)
    
    # --- 7. LÆ¯U Káº¾T QUáº¢ ---
    real_save_path = os.path.join(args.output_dir, f"{sample_id}_orig.npy")
    recon_save_path = os.path.join(args.output_dir, f"{sample_id}_recon.npy")
    
    np.save(real_save_path, real_pose_np)
    np.save(recon_save_path, recon_final)
    
    print("\n" + "="*50)
    print(f"ğŸ“Š Káº¾T QUáº¢ KIá»‚M TRA (MSE): {mse:.8f}")
    if mse < 0.001:
        print("âœ… ÄÃ¡nh giÃ¡: Ráº¤T Tá»T (Stage 1 hoÃ n háº£o)")
    elif mse < 0.01:
        print("âš ï¸ ÄÃ¡nh giÃ¡: Táº M á»”N (CÃ³ thá»ƒ máº¥t chi tiáº¿t nhá»)")
    else:
        print("âŒ ÄÃ¡nh giÃ¡: KÃ‰M (Cáº§n kiá»ƒm tra láº¡i Normalize hoáº·c Training)")
    print("="*50)
    
    print(f"\nğŸ‘‰ 1. File gá»‘c: {real_save_path}")
    print(f"ğŸ‘‰ 2. File tÃ¡i táº¡o: {recon_save_path}")
    print(f"\nğŸ’¡ Cháº¡y lá»‡nh visualize Ä‘á»ƒ xem video:")
    print(f"python training/visualize_single_pose.py --npy_path {recon_save_path} --output_video {sample_id}_check.mp4")

if __name__ == '__main__':
    main()