import torch
import numpy as np
import argparse
import os
import sys
import glob

# --- Import Modules ---
try:
    sys.path.append(os.getcwd()) 
    from models.fml.autoencoder import UnifiedPoseAutoencoder
    # Import logic chuáº©n tá»« file chá»‹ gá»­i
    from data_preparation import normalize_pose, denormalize_pose, load_sample
except ImportError as e:
    print(f"âŒ Lá»—i Import: {e}")
    sys.exit(1)

def main():
    # --- 1. Cáº¤U HÃŒNH THAM Sá» ---
    parser = argparse.ArgumentParser(description='Kiá»ƒm tra cháº¥t lÆ°á»£ng Autoencoder (Stage 1)')
    parser.add_argument('--data_dir', type=str, required=True, help='Folder chá»©a normalization_stats.npz vÃ  train/dev/test')
    parser.add_argument('--autoencoder_checkpoint', type=str, required=True, help='ÄÆ°á»ng dáº«n file .pt')
    parser.add_argument('--output_dir', type=str, default='check_stage1_output')
    parser.add_argument('--latent_dim', type=int, default=256)
    parser.add_argument('--hidden_dim', type=int, default=512)

    args = parser.parse_args()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    os.makedirs(args.output_dir, exist_ok=True)

    # --- 2. LOAD STATS (Theo Ä‘Ãºng dictionary 4 keys chá»‹ Ä‘Ã£ viáº¿t) ---
    stats_path = os.path.join(args.data_dir, "normalization_stats.npz")
    if not os.path.exists(stats_path):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y stats táº¡i {stats_path}")
        return
        
    print(f"ğŸ“Š Loading Grouped Stats tá»«: {stats_path}")
    s = np.load(stats_path)
    # Táº¡o dict stats Ä‘Ãºng signature hÃ m cá»§a chá»‹
    stats = {
        'manual_mean': s['manual_mean'], 'manual_std': s['manual_std'],
        'nmm_mean': s['nmm_mean'], 'nmm_std': s['nmm_std']
    }

    # --- 3. LOAD MODEL ---
    ae = UnifiedPoseAutoencoder(pose_dim=214, latent_dim=args.latent_dim, hidden_dim=args.hidden_dim).to(device)
    ckpt = torch.load(args.autoencoder_checkpoint, map_location=device)
    ae.load_state_dict(ckpt['model_state_dict'] if 'model_state_dict' in ckpt else ckpt)
    ae.eval()
    print("âœ… Load model thÃ nh cÃ´ng!")

    # --- 4. LOAD FILE DATA MáºªU ---
    # Sá»­ dá»¥ng hÃ m load_sample cá»§a chá»‹ Ä‘á»ƒ láº¥y Ä‘Ãºng 214D (Pose + NMM)
    print(f"ğŸ” Äang tÃ¬m file máº«u trong {args.data_dir}/train/poses...")
    pose_files = glob.glob(os.path.join(args.data_dir, "train/poses/*.npz"))
    if not pose_files:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y file dá»¯ liá»‡u máº«u!")
        return
    
    # Láº¥y video_id tá»« file Ä‘áº§u tiÃªn tÃ¬m tháº¥y
    video_id = os.path.basename(pose_files[0]).replace('.npz', '')
    real_pose_np, T = load_sample(video_id, os.path.join(args.data_dir, "train"))
    print(f"âœ… ÄÃ£ load video: {video_id} (T={T})")

    # --- 5. NORMALIZE (DÃ¹ng hÃ m normalize_pose cá»§a chá»‹) ---
    real_pose_norm = normalize_pose(real_pose_np, stats)
    real_pose_input = torch.tensor(real_pose_norm, dtype=torch.float32).to(device).unsqueeze(0)

    # --- 6. INFERENCE (TÃI Táº O) ---
    print("ğŸ”„ Äang cháº¡y qua Autoencoder...")
    with torch.no_grad():
        recon_norm, _ = ae(real_pose_input)

    # --- 7. DENORMALIZE & SAVE ---
    recon_norm_np = recon_norm.squeeze(0).cpu().numpy()
    
    # DÃ¹ng hÃ m denormalize_pose cá»§a chá»‹ Ä‘á»ƒ giáº£i chuáº©n hÃ³a vá» tá»a Ä‘á»™ gá»‘c
    recon_final = denormalize_pose(recon_norm_np, stats) 
    
    # LÆ°u káº¿t quáº£
    real_save_path = os.path.join(args.output_dir, "original_sample.npy")
    recon_save_path = os.path.join(args.output_dir, "reconstructed_sample.npy")
    np.save(real_save_path, real_pose_np)
    np.save(recon_save_path, recon_final)
    
    # TÃ­nh MSE nhanh Ä‘á»ƒ chá»‹ xem "sá»©c khá»e"
    mse = np.mean((real_pose_np - recon_final)**2)
    print("\n" + "="*40)
    print(f"ğŸ“‰ Reconstruction MSE: {mse:.8f}")
    print(f"ğŸ“‚ Káº¿t quáº£ lÆ°u táº¡i: {args.output_dir}")
    print("="*40)

if __name__ == '__main__':
    main()