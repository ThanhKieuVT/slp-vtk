import torch
import numpy as np
import argparse
import os
import sys
import glob

# --- Import Modules (X·ª≠ l√Ω ƒë∆∞·ªùng d·∫´n Colab) ---
try:
    sys.path.append(os.getcwd()) 
    from models.fml.autoencoder import UnifiedPoseAutoencoder
    from data_preparation import denormalize_pose 
except ImportError as e:
    print(f"‚ùå L·ªói Import: {e}")
    print("üí° G·ª£i √Ω: Ch·ªã nh·ªõ ƒë·∫∑t file n√†y ·ªü th∆∞ m·ª•c g·ªëc (c√πng c·∫•p v·ªõi folder 'models' v√† file 'data_preparation.py')")
    sys.exit(1)

def main():
    # --- 1. C·∫§U H√åNH THAM S·ªê ---
    parser = argparse.ArgumentParser(description='Ki·ªÉm tra ch·∫•t l∆∞·ª£ng Autoencoder (Stage 1)')
    
    parser.add_argument('--data_dir', type=str, required=True,
                        help='Folder ch·ª©a file normalization_stats.npz')
    parser.add_argument('--autoencoder_checkpoint', type=str, required=True,
                        help='ƒê∆∞·ªùng d·∫´n file .pt c·ªßa Autoencoder')
    parser.add_argument('--output_dir', type=str, default='check_stage1_output',
                        help='N∆°i l∆∞u file k·∫øt qu·∫£')
    
    parser.add_argument('--latent_dim', type=int, default=256)
    parser.add_argument('--hidden_dim', type=int, default=512)
    parser.add_argument('--pose_dim', type=int, default=214, help='S·ªë l∆∞·ª£ng feature c·ªßa Pose')

    args = parser.parse_args()
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üöÄ ƒêang ki·ªÉm tra tr√™n device: {device}")
    os.makedirs(args.output_dir, exist_ok=True)

    # --- 2. LOAD MODEL ---
    print(f"üì¶ Loading Autoencoder (pose_dim={args.pose_dim})...")
    ae = UnifiedPoseAutoencoder(
        pose_dim=args.pose_dim, 
        latent_dim=args.latent_dim, 
        hidden_dim=args.hidden_dim
    ).to(device)

    try:
        ckpt = torch.load(args.autoencoder_checkpoint, map_location=device)
        state_dict = ckpt['model_state_dict'] if 'model_state_dict' in ckpt else ckpt
        ae.load_state_dict(state_dict, strict=True)
        print("‚úÖ Load weights th√†nh c√¥ng!")
        ae.eval()
    except Exception as e:
        print(f"‚ùå L·ªói load checkpoint: {e}")
        return

    # --- 3. LOAD STATS ---
    stats_path = os.path.join(args.data_dir, "normalization_stats.npz")
    if not os.path.exists(stats_path):
        stats_path = os.path.join(args.data_dir, "../normalization_stats.npz")
    
    if not os.path.exists(stats_path):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y normalization_stats.npz")
        return
        
    stats = np.load(stats_path)
    mean = torch.tensor(stats['mean']).float().to(device)
    std = torch.tensor(stats['std']).float().to(device)

    # --- 4. T√åM & LOAD FILE DATA M·∫™U ---
    npy_files = glob.glob(os.path.join(args.data_dir, "**/*.npy"), recursive=True)
    valid_files = [f for f in npy_files if all(k not in f for k in ["stats", "output", "check"])]
    
    if not valid_files:
        print("‚ùå Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu n√†o!")
        return

    sample_file = valid_files[0]
    print(f"‚úÖ ƒê√£ ch·ªçn file m·∫´u: {sample_file}")
    
    real_pose_np = np.load(sample_file)
    real_pose_np = np.nan_to_num(real_pose_np) # X·ª≠ l√Ω NaN r√°c

    if real_pose_np.shape[-1] != args.pose_dim:
        print(f"‚ö†Ô∏è C·∫£nh b√°o: Shape file ({real_pose_np.shape[-1]}) kh√°c v·ªõi c·∫•u h√¨nh pose_dim ({args.pose_dim})")
        # T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh n·∫øu ch·ªã l·ª° nh·∫≠p sai pose_dim
        # real_pose_np = real_pose_np[:, :args.pose_dim] 

    # --- 5. NORMALIZE & INFERENCE ---
    real_pose = torch.tensor(real_pose_np, dtype=torch.float32).to(device)
    real_pose_norm = (real_pose - mean) / (std + 1e-6)
    real_pose_input = real_pose_norm.unsqueeze(0)

    print("üîÑ ƒêang ch·∫°y qua Autoencoder...")
    with torch.no_grad():
        recon_norm, _ = ae(real_pose_input)

    # --- 6. DENORMALIZE & EVALUATE ---
    recon_np = recon_norm.squeeze(0).cpu().numpy()
    recon_final = denormalize_pose(recon_np, stats['mean'], stats['std']) 

    # T√çNH TO√ÅN MSE (C√ÄNG NH·ªé C√ÄNG T·ªêT)
    mse = np.mean((real_pose_np - recon_final)**2)
    
    # --- 7. L∆ØU K·∫æT QU·∫¢ ---
    real_save_path = os.path.join(args.output_dir, "original_sample.npy")
    recon_save_path = os.path.join(args.output_dir, "reconstructed_sample.npy")
    
    np.save(real_save_path, real_pose_np)
    np.save(recon_save_path, recon_final)
    
    print("\n" + "="*50)
    print(f"üìä K·∫æT QU·∫¢ KI·ªÇM TRA:")
    print(f"   üîπ MSE Error: {mse:.8f}")
    if mse < 0.001:
        print("   üîπ ƒê√°nh gi√°: R·∫§T T·ªêT (H·∫ßu nh∆∞ kh√¥ng m·∫•t th√¥ng tin)")
    elif mse < 0.01:
        print("   üîπ ƒê√°nh gi√°: T·ªêT (C√≥ th·ªÉ d√πng cho Stage 2)")
    else:
        print("   üîπ ƒê√°nh gi√°: C·∫¢NH B√ÅO (T√°i t·∫°o k√©m, c·∫ßn train th√™m)")
    
    print("-" * 50)
    print(f"   üìÅ Files ƒë√£ l∆∞u t·∫°i: {args.output_dir}")
    print("="*50)
    print(f"\nüëâ Ch·∫°y l·ªánh n√†y ƒë·ªÉ xem video so s√°nh:")
    print(f"python training/visualize_single_pose.py --npy_path {recon_save_path} --output_video check_ae_result.mp4")

if __name__ == '__main__':
    main()