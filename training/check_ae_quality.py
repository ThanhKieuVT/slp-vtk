"""
Script: Check Autoencoder Reconstruction Quality (Colab Compatible)
Má»¥c Ä‘Ã­ch: "KhÃ¡m sá»©c khá»e" Autoencoder Stage 1.
Logic: 
1. Láº¥y 1 file pose tháº­t (.npy).
2. Chuáº©n hÃ³a (Normalize) báº±ng stats cá»§a chá»‹.
3. ÄÆ°a qua Autoencoder Ä‘á»ƒ tÃ¡i táº¡o.
4. Giáº£i chuáº©n hÃ³a (Denormalize) vá» tá»a Ä‘á»™ gá»‘c.
5. LÆ°u 2 file (Gá»‘c vs TÃ¡i táº¡o) Ä‘á»ƒ so sÃ¡nh.
"""

import torch
import numpy as np
import argparse
import os
import sys
import glob

# --- Import Modules (Xá»­ lÃ½ Ä‘Æ°á»ng dáº«n Colab) ---
try:
    sys.path.append(os.getcwd()) 
    # Import Model
    from models.fml.autoencoder import UnifiedPoseAutoencoder
    # Import hÃ m denormalize chuáº©n tá»« file chá»‹ gá»­i
    from data_preparation import denormalize_pose 
except ImportError as e:
    print(f"âŒ Lá»—i Import: {e}")
    print("ğŸ’¡ Gá»£i Ã½: Chá»‹ nhá»› Ä‘áº·t file nÃ y á»Ÿ thÆ° má»¥c gá»‘c (cÃ¹ng cáº¥p vá»›i folder 'models' vÃ  file 'data_preparation.py')")
    sys.exit(1)

def main():
    # --- 1. Cáº¤U HÃŒNH THAM Sá» ---
    parser = argparse.ArgumentParser(description='Kiá»ƒm tra cháº¥t lÆ°á»£ng Autoencoder (Stage 1)')
    
    parser.add_argument('--data_dir', type=str, required=True,
                        help='Folder chá»©a file normalization_stats.npz vÃ  cÃ¡c folder train/dev/test')
    parser.add_argument('--autoencoder_checkpoint', type=str, required=True,
                        help='ÄÆ°á»ng dáº«n file .pt cá»§a Autoencoder')
    parser.add_argument('--output_dir', type=str, default='check_stage1_output',
                        help='NÆ¡i lÆ°u file káº¿t quáº£')
    
    # Config Model (Pháº£i khá»›p lÃºc train)
    parser.add_argument('--latent_dim', type=int, default=256)
    parser.add_argument('--hidden_dim', type=int, default=512)

    args = parser.parse_args()
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸš€ Äang kiá»ƒm tra trÃªn device: {device}")
    os.makedirs(args.output_dir, exist_ok=True)

    # --- 2. LOAD MODEL ---
    print(f"ğŸ“¦ Loading Autoencoder tá»«: {args.autoencoder_checkpoint}")
    ae = UnifiedPoseAutoencoder(
        pose_dim=214, # -> Combine 214D
        latent_dim=args.latent_dim, 
        hidden_dim=args.hidden_dim
    ).to(device)

    try:
        ckpt = torch.load(args.autoencoder_checkpoint, map_location=device)
        # Xá»­ lÃ½ dict an toÃ n
        state_dict = ckpt['model_state_dict'] if 'model_state_dict' in ckpt else ckpt
        ae.load_state_dict(state_dict, strict=True)
        print("âœ… Load weights thÃ nh cÃ´ng (Strict Mode)!")
        ae.eval()
    except Exception as e:
        print(f"âŒ Lá»—i load checkpoint: {e}")
        return

    # --- 3. LOAD STATS ---
    # Code sáº½ tá»± tÃ¬m file stats trong data_dir hoáº·c thÆ° má»¥c cha
    stats_path = os.path.join(args.data_dir, "normalization_stats.npz")
    if not os.path.exists(stats_path):
        stats_path = os.path.join(args.data_dir, "../normalization_stats.npz")
    
    if not os.path.exists(stats_path):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y normalization_stats.npz táº¡i {args.data_dir}")
        return
        
    print(f"ğŸ“Š Loading Stats tá»«: {stats_path}")
    stats = np.load(stats_path)
    # Load lÃªn GPU Ä‘á»ƒ tÃ­nh toÃ¡n cho nhanh
    mean = torch.tensor(stats['mean']).float().to(device)
    std = torch.tensor(stats['std']).float().to(device)

    # --- 4. TÃŒM & LOAD FILE DATA MáºªU ---
    # Tá»± Ä‘á»™ng quÃ©t tÃ¬m 1 file .npy báº¥t ká»³ trong data_dir Ä‘á»ƒ test
    print(f"ğŸ” Äang tÃ¬m file .npy máº«u...")
    npy_files = glob.glob(os.path.join(args.data_dir, "**/*.npy"), recursive=True)
    
    # Lá»c bá» file rÃ¡c (stats, output cÅ©)
    valid_files = [f for f in npy_files if "stats" not in f and "output" not in f and "check" not in f]
    
    if not valid_files:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y file .npy dá»¯ liá»‡u nÃ o Ä‘á»ƒ test!")
        return

    sample_file = valid_files[0]
    print(f"âœ… ÄÃ£ chá»n file máº«u: {sample_file}")
    
    try:
        real_pose_np = np.load(sample_file) # [T, 214]
    except Exception as e:
        print(f"âŒ Lá»—i Ä‘á»c file .npy: {e}")
        return

    # Chuyá»ƒn sang Tensor
    real_pose = torch.tensor(real_pose_np, dtype=torch.float32).to(device)

    # --- 5. NORMALIZE (MÃ´ phá»ng Ä‘áº§u vÃ o Model) ---
    # CÃ´ng thá»©c: (X - Mean) / Std
    real_pose_norm = (real_pose - mean) / (std + 1e-6)
    
    # ThÃªm batch dimension: [T, 214] -> [1, T, 214]
    real_pose_input = real_pose_norm.unsqueeze(0)

    # --- 6. INFERENCE (TÃI Táº O) ---
    print("ğŸ”„ Äang cháº¡y qua Autoencoder...")
    with torch.no_grad():
        recon_norm, _ = ae(real_pose_input)

    # --- 7. DENORMALIZE & SAVE ---
    print("ğŸ’¾ Äang lÆ°u káº¿t quáº£...")
    
    # 7.1. LÆ°u Ground Truth (Dá»¯ liá»‡u gá»‘c)
    real_save_path = os.path.join(args.output_dir, "original_sample.npy")
    np.save(real_save_path, real_pose_np)
    
    # 7.2. LÆ°u Reconstruction (Káº¿t quáº£ tÃ¡i táº¡o)
    recon_np = recon_norm.squeeze(0).cpu().numpy()
    
    # DÃ¹ng hÃ m cá»§a chá»‹ Ä‘á»ƒ giáº£i chuáº©n hÃ³a: X_new * Std + Mean
    recon_final = denormalize_pose(recon_np, stats['mean'], stats['std']) 
    
    recon_save_path = os.path.join(args.output_dir, "reconstructed_sample.npy")
    np.save(recon_save_path, recon_final)
    
    print("\n" + "="*40)
    print("ğŸ‰ HOÃ€N Táº¤T! Káº¿t quáº£ Ä‘Ã£ lÆ°u táº¡i:")
    print(f"   1. Gá»‘c (GT):      {real_save_path}")
    print(f"   2. TÃ¡i táº¡o (Rec): {recon_save_path}")
    print("="*40)
    print("\nğŸ‘‰ COPY Lá»†NH SAU Äá»‚ XEM VIDEO SO SÃNH:")
    print(f"python training/visualize_single_pose.py --npy_path {recon_save_path} --output_video check_ae_result.mp4")

if __name__ == '__main__':
    main()