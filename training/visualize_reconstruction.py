import numpy as np
import cv2
import argparse
import os
from tqdm import tqdm

# --- 1. ƒê·ªäNH NGHƒ®A KHUNG X∆Ø∆†NG (PHOENIX-14T) ---
# Body (0-24) nh∆∞ng ch·ªâ v·∫Ω c√°c kh·ªõp ch√≠nh
BODY_CONNECTIONS = [
    (0, 1), (1, 2), (2, 3), (3, 4),      # Spine
    (1, 5), (5, 6), (6, 7),              # Left Arm
    (1, 8), (8, 9), (9, 10),             # Right Arm
    (0, 11), (11, 12), (12, 13),         # Left Leg
    (0, 14), (14, 15), (15, 16),         # Right Leg
    (0, 17), (17, 18), (18, 19), (19, 20) # Head
]

# Hands (21 points each)
HAND_CONNECTIONS = [
    (0, 1), (1, 2), (2, 3), (3, 4),      # Thumb
    (0, 5), (5, 6), (6, 7), (7, 8),      # Index
    (0, 9), (9, 10), (10, 11), (11, 12), # Middle
    (0, 13), (13, 14), (14, 15), (15, 16), # Ring
    (0, 17), (17, 18), (18, 19), (19, 20)  # Pinky
]

def smart_scale_coords(coords, width, height):
    """
    T·ª± ƒë·ªông scale t·ªça ƒë·ªô:
    - N·∫øu max < 1.5 -> D·ªØ li·ªáu ƒëang Norm (0-1) -> Nh√¢n v·ªõi W, H
    - N·∫øu max > 1.5 -> D·ªØ li·ªáu ƒëang Pixel -> Gi·ªØ nguy√™n
    """
    coords_scaled = coords.copy()
    max_val = np.max(np.abs(coords))
    
    if max_val <= 1.5:
        # Data ƒëang ·ªü d·∫°ng [0, 1], c·∫ßn scale l√™n
        coords_scaled[:, 0] = coords[:, 0] * width
        coords_scaled[:, 1] = coords[:, 1] * height
    else:
        # Data c√≥ v·∫ª ƒë√£ l√† pixel, gi·ªØ nguy√™n (ho·∫∑c resize n·∫øu c·∫ßn)
        pass
        
    return coords_scaled.astype(np.int32)

def draw_skeleton(frame, keypoints, color=(0, 255, 0), thickness=2):
    """V·∫Ω skeleton l√™n frame ƒëen"""
    # T√°ch c√°c b·ªô ph·∫≠n (D·ª±a tr√™n 75 keypoints chu·∫©n)
    # [0-24]: Body, [25-45]: Left Hand, [46-66]: Right Hand
    body = keypoints[:25]
    left_hand = keypoints[25:46]
    right_hand = keypoints[46:67]
    
    # 1. Draw Body
    for i, j in BODY_CONNECTIONS:
        if i < len(body) and j < len(body):
            pt1, pt2 = body[i], body[j]
            # Ch·ªâ v·∫Ω n·∫øu ƒëi·ªÉm kh√¥ng ph·∫£i (0,0)
            if np.sum(pt1) > 0 and np.sum(pt2) > 0:
                cv2.line(frame, tuple(pt1), tuple(pt2), color, thickness)
                
    # 2. Draw Hands (M·∫£nh h∆°n ch√∫t cho ƒë·∫πp)
    hand_thickness = max(1, thickness - 1)
    
    # Left Hand
    for i, j in HAND_CONNECTIONS:
        if i < len(left_hand) and j < len(left_hand):
            pt1, pt2 = left_hand[i], left_hand[j]
            if np.sum(pt1) > 0 and np.sum(pt2) > 0:
                cv2.line(frame, tuple(pt1), tuple(pt2), color, hand_thickness)

    # Right Hand
    for i, j in HAND_CONNECTIONS:
        if i < len(right_hand) and j < len(right_hand):
            pt1, pt2 = right_hand[i], right_hand[j]
            if np.sum(pt1) > 0 and np.sum(pt2) > 0:
                cv2.line(frame, tuple(pt1), tuple(pt2), color, hand_thickness)

    return frame

def create_comparison_video(original_path, reconstructed_path, output_video, fps=25):
    print("üìÇ ƒêang load d·ªØ li·ªáu...")
    original = np.load(original_path)       # [T, 214]
    reconstructed = np.load(reconstructed_path) # [T, 214]
    
    T = len(original)
    
    # Ch·ªâ l·∫•y 150 chi·ªÅu ƒë·∫ßu (Pose 75x2), b·ªè qua NMM (Facial) l√∫c v·∫Ω x∆∞∆°ng
    # Reshape v·ªÅ [T, 75, 2]
    original_kp = original[:, :150].reshape(T, 75, 2)
    recon_kp = reconstructed[:, :150].reshape(T, 75, 2)
    
    # C·∫•u h√¨nh Video
    H, W = 512, 512 # ƒê·ªô ph√¢n gi·∫£i hi·ªÉn th·ªã
    frame_size = (W * 2, H) # Side-by-side
    
    # Codec cho MP4
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video, fourcc, fps, frame_size)
    
    print(f"üé¨ ƒêang render video {T} frames...")
    print(f"   Mode: {'Normalized [0-1]' if np.max(original_kp) <= 1.5 else 'Pixel Coords'}")

    for t in tqdm(range(T)):
        # T·∫°o n·ªÅn ƒëen
        frame_orig = np.zeros((H, W, 3), dtype=np.uint8)
        frame_recon = np.zeros((H, W, 3), dtype=np.uint8)
        
        # Scale t·ªça ƒë·ªô cho kh·ªõp v·ªõi khung h√¨nh H, W
        kp_orig = smart_scale_coords(original_kp[t], W, H)
        kp_recon = smart_scale_coords(recon_kp[t], W, H)
        
        # V·∫Ω Skeleton
        # G·ªëc: M√†u Xanh L√° (Green)
        draw_skeleton(frame_orig, kp_orig, color=(0, 255, 0))
        # T√°i t·∫°o: M√†u ƒê·ªè (Red)
        draw_skeleton(frame_recon, kp_recon, color=(0, 0, 255))
        
        # Th√™m nh√£n (Labels)
        cv2.putText(frame_orig, "ORIGINAL (GT)", (20, 40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(frame_recon, "RECONSTRUCTED", (20, 40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        
        # S·ªë Frame
        cv2.putText(frame_orig, f"Frame: {t}/{T}", (20, H-20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        # Gh√©p 2 ·∫£nh l·∫°i (Tr√°i - Ph·∫£i)
        combined = np.hstack((frame_orig, frame_recon))
        out.write(combined)
        
    out.release()
    print(f"\n‚úÖ Xong! Video l∆∞u t·∫°i: {output_video}")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--original', type=str, required=True, help='File .npy g·ªëc')
    parser.add_argument('--reconstructed', type=str, required=True, help='File .npy t√°i t·∫°o')
    parser.add_argument('--output_video', type=str, default='comparison.mp4')
    parser.add_argument('--fps', type=int, default=25)
    
    args = parser.parse_args()
    
    if not os.path.exists(args.original):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file g·ªëc: {args.original}")
        return
        
    create_comparison_video(args.original, args.reconstructed, args.output_video, args.fps)

if __name__ == '__main__':
    main()