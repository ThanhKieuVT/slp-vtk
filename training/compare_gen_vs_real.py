"""
Script so sÃ¡nh Real vs Generated Pose (PhiÃªn báº£n Chuáº©n XÃ¡c)
Chá»©c nÄƒng:
1. Load pose tháº­t (Real) tá»« ID vÃ  pose giáº£ (Gen) tá»« file .npy
2. TÃ¡ch bá» cÃ¡c thÃ nh pháº§n phi tá»a Ä‘á»™ (AUs, Head, Gaze) trong vector 214 chiá»u.
3. Váº½ video so sÃ¡nh dáº¡ng Point Cloud (Cháº¥m Ä‘iá»ƒm).
"""
import os
import sys
import argparse
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation

# ThÃªm Ä‘Æ°á»ng dáº«n hiá»‡n táº¡i Ä‘á»ƒ import module
sys.path.append(os.getcwd())

try:
    # Cá»‘ gáº¯ng import hÃ m load chuáº©n tá»« file cá»§a chá»‹
    from data_preparation import load_sample
except ImportError:
    print("âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file 'data_preparation.py'.")
    print("ğŸ’¡ HÃ£y Ä‘áº£m báº£o chá»‹ cháº¡y lá»‡nh tá»« thÆ° má»¥c gá»‘c cá»§a project.")
    sys.exit(1)

# === 1. HÃ€M TÃCH Tá»ŒA Äá»˜ (Cá»T LÃ•I) ===
def extract_visual_coordinates(pose_214):
    """
    Input: [T, 214] vector chá»©a lung tung cáº£ tá»a Ä‘á»™ láº«n sá»‘ Ä‘o.
    Output: [T, N_points, 2] chá»‰ chá»©a tá»a Ä‘á»™ X,Y Ä‘á»ƒ váº½.
    
    Cáº¥u trÃºc vector 214 chiá»u (dá»±a trÃªn data_preparation.py):
    - 0   -> 150: Body + Hands (75 Ä‘iá»ƒm x 2 chiá»u) -> Láº¤Y
    - 150 -> 167: Facial AUs (17 sá»‘)               -> Bá»
    - 167 -> 170: Head Pose (3 sá»‘)                 -> Bá»
    - 170 -> 174: Eye Gaze (4 sá»‘)                  -> Bá»
    - 174 -> 214: Mouth (20 Ä‘iá»ƒm x 2 chiá»u)        -> Láº¤Y
    """
    # 1. Láº¥y pháº§n Body + Hands
    body_hands_flat = pose_214[:, :150] # [T, 150]
    
    # 2. Láº¥y pháº§n Mouth
    mouth_flat = pose_214[:, 174:214]   # [T, 40]
    
    # 3. Gá»™p láº¡i
    visual_flat = np.concatenate([body_hands_flat, mouth_flat], axis=1) # [T, 190]
    
    # 4. Reshape thÃ nh tá»a Ä‘á»™ (X, Y)
    # Tá»•ng sá»‘ Ä‘iá»ƒm = 190 / 2 = 95 Ä‘iá»ƒm
    visual_points = visual_flat.reshape(len(pose_214), -1, 2) # [T, 95, 2]
    
    return visual_points

# === 2. HÃ€M Váº¼ VIDEO SO SÃNH ===
def create_comparison_video(real_pose_raw, gen_pose_raw, output_path, video_id):
    print(f"ğŸ”„ Äang xá»­ lÃ½ data cho ID: {video_id}")
    
    # 1. Cáº¯t Ä‘á»™ dÃ i cho báº±ng nhau
    min_len = min(len(real_pose_raw), len(gen_pose_raw))
    real_raw = real_pose_raw[:min_len]
    gen_raw = gen_pose_raw[:min_len]
    
    # 2. TrÃ­ch xuáº¥t tá»a Ä‘á»™ sáº¡ch
    real_data = extract_visual_coordinates(real_raw)
    gen_data = extract_visual_coordinates(gen_raw)
    
    print(f"ğŸ¬ Äang render video ({min_len} frames)...")
    
    # 3. Setup khung hÃ¬nh (2 bÃªn)
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
    
    # TÃ­nh giá»›i háº¡n khung hÃ¬nh (Scale) dá»±a trÃªn dá»¯ liá»‡u tháº­t
    all_x = real_data[:, :, 0].flatten()
    all_y = real_data[:, :, 1].flatten()
    
    # Lá»c bá» Ä‘iá»ƒm 0 (padding) Ä‘á»ƒ tÃ­nh scale chuáº©n
    valid_mask = (all_x > 0.01) & (all_y > 0.01)
    
    if valid_mask.sum() > 0:
        x_min, x_max = all_x[valid_mask].min(), all_x[valid_mask].max()
        y_min, y_max = all_y[valid_mask].min(), all_y[valid_mask].max()
    else:
        # Fallback náº¿u data lá»—i
        x_min, x_max, y_min, y_max = 0, 1, 0, 1
        
    # Ná»›i rá»™ng viá»n tÃ­ cho Ä‘áº¹p
    margin_w = (x_max - x_min) * 0.1
    margin_h = (y_max - y_min) * 0.1
    
    for ax in [ax1, ax2]:
        ax.set_xlim(x_min - margin_w, x_max + margin_w)
        ax.set_ylim(y_max + margin_h, y_min - margin_h) # Äáº£o trá»¥c Y (áº£nh gá»‘c gá»‘c toáº¡ Ä‘á»™ á»Ÿ trÃªn cÃ¹ng)
        ax.axis('off') # Táº¯t trá»¥c sá»‘
        
    ax1.set_title("REAL (Ground Truth)", color='darkred', fontweight='bold')
    ax2.set_title("GENERATED (AI)", color='darkblue', fontweight='bold')
    fig.suptitle(f"Video ID: {video_id}", fontsize=10)
    
    # 4. Init Artists (CÃ¡c cháº¥m Ä‘iá»ƒm)
    # Real = Äá», Gen = Xanh
    scat_real = ax1.scatter([], [], s=15, c='red', alpha=0.7, edgecolors='none')
    scat_gen = ax2.scatter([], [], s=15, c='blue', alpha=0.7, edgecolors='none')
    
    def update(frame):
        # Láº¥y frame t
        p_real = real_data[frame]
        p_gen = gen_data[frame]
        
        # Lá»c bá» cÃ¡c Ä‘iá»ƒm rÃ¡c (tá»a Ä‘á»™ 0,0 do padding hoáº·c missing)
        # Äiá»ƒm há»£p lá»‡ lÃ  Ä‘iá»ƒm cÃ³ tá»•ng trá»‹ tuyá»‡t Ä‘á»‘i > 0
        mask_r = (np.abs(p_real).sum(axis=1) > 1e-3)
        mask_g = (np.abs(p_gen).sum(axis=1) > 1e-3)
        
        scat_real.set_offsets(p_real[mask_r])
        scat_gen.set_offsets(p_gen[mask_g])
        
        return scat_real, scat_gen

    # Render
    ani = animation.FuncAnimation(fig, update, frames=min_len, blit=True, interval=50)
    ani.save(output_path, writer='ffmpeg', fps=20)
    print(f"âœ… HOÃ€N Táº¤T! Video lÆ°u táº¡i: {output_path}")
    plt.close()

# === 3. MAIN ===
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--gen_path', type=str, required=True, help="ÄÆ°á»ng dáº«n file .npy sinh ra tá»« model")
    parser.add_argument('--data_dir', type=str, required=True, help="ThÆ° má»¥c chá»©a data gá»‘c (processed_data/data)")
    parser.add_argument('--video_id', type=str, required=True, help="TÃªn ID cá»§a video gá»‘c Ä‘á»ƒ so sÃ¡nh")
    parser.add_argument('--split', type=str, default='train', help="Split chá»©a video gá»‘c (train/dev/test)")
    parser.add_argument('--output_video', type=str, default='compare_final.mp4', help="TÃªn file video Ä‘áº§u ra")
    
    args = parser.parse_args()
    
    # 1. Load Gen
    if not os.path.exists(args.gen_path):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file Gen: {args.gen_path}")
        return
    gen_pose = np.load(args.gen_path)
    print(f"ğŸ“‚ Loaded Gen Pose: {gen_pose.shape}")
    
    # 2. Load Real
    split_dir = os.path.join(args.data_dir, args.split)
    if not os.path.exists(split_dir):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c split: {split_dir}")
        return
        
    print(f"ğŸ“‚ Loading Real ID: {args.video_id}...")
    real_pose, T = load_sample(args.video_id, split_dir)
    
    if real_pose is None:
        print("âŒ KhÃ´ng load Ä‘Æ°á»£c Pose gá»‘c! Kiá»ƒm tra láº¡i ID hoáº·c Ä‘Æ°á»ng dáº«n Data.")
        return
    
    print(f"ğŸ“Š Real Pose Shape: {real_pose.shape}")
    
    # 3. Táº¡o Video
    create_comparison_video(real_pose, gen_pose, args.output_video, args.video_id)

if __name__ == '__main__':
    main()