# TÃªn file: visualize_pose.py
import os
import argparse
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from matplotlib.lines import Line2D

# --- Báº¢N Äá»’ Káº¾T Ná»I (SKELETON MAP) ---
# Dá»±a trÃªn file 1_extract_all_features.py
# 0-32: MediaPipe Holistic Pose (33 Ä‘iá»ƒm)
# 33-53: MediaPipe Left Hand (21 Ä‘iá»ƒm)
# 54-74: MediaPipe Right Hand (21 Ä‘iá»ƒm)
# --- (Tá»”NG = 75 ÄIá»‚M "MANUAL") ---
# 75-94: 20 Ä‘iá»ƒm Miá»‡ng (tá»« NMMs)

# 1. Káº¿t ná»‘i 21 Ä‘iá»ƒm bÃ n tay (dÃ¹ng chung)
HAND_CONNECTIONS = [
    (0, 1), (1, 2), (2, 3), (3, 4),         # NgÃ³n cÃ¡i
    (0, 5), (5, 6), (6, 7), (7, 8),         # NgÃ³n trá»
    (0, 9), (9, 10), (10, 11), (11, 12),    # NgÃ³n giá»¯a
    (0, 13), (13, 14), (14, 15), (15, 16),  # NgÃ³n Ã¡p Ãºt
    (0, 17), (17, 18), (18, 19), (19, 20)   # NgÃ³n Ãºt
]

# 2. Káº¿t ná»‘i ThÃ¢n + Máº·t (Holistic Pose 33 Ä‘iá»ƒm - Bá» QUA CHÃ‚N)
# ÄÃ¢y lÃ  cÃ¡c káº¿t ná»‘i cho pháº§n thÃ¢n trÃªn vÃ  máº·t
# Chá»‰ sá»‘ (index) tham chiáº¿u Ä‘áº¿n MediaPipe
POSE_CONNECTIONS_UPPER_BODY = [
    # Máº·t
    (0, 1), (1, 2), (2, 3), (3, 7), (0, 4), (4, 5), (5, 6), (6, 8),
    (9, 10), 
    # ThÃ¢n
    (11, 12), (12, 14), (14, 16), (11, 13), (13, 15),
    (11, 23), (12, 24), (23, 24),
    # Káº¿t ná»‘i tay tá»« thÃ¢n (quan trá»ng)
    (12, 11) # Vai
]

# 3. Káº¿t ná»‘i 20 Ä‘iá»ƒm miá»‡ng (tá»« NMMs)
# Láº¥y tá»« hÃ m _extract_mouth (indices 61, 146, 91, ...)
MOUTH_OUTER_LIP = list(zip(range(0, 11), range(1, 12))) + [(11, 0)]
MOUTH_INNER_LIP = list(zip(range(12, 19), range(13, 20))) + [(19, 12)]
MOUTH_CONNECTIONS_20 = MOUTH_OUTER_LIP + MOUTH_INNER_LIP

# --- Tá»”NG Há»¢P Báº¢N Äá»’ Káº¾T Ná»I ---
ALL_CONNECTIONS = []

# 1. ThÃ¢n + Máº·t (Indices 0-32)
ALL_CONNECTIONS.extend([
    {'indices': (start, end), 'offset': 0, 'color': 'gray', 'lw': 2}
    for (start, end) in POSE_CONNECTIONS_UPPER_BODY
])

# 2. Tay TrÃ¡i (Indices 33-53)
ALL_CONNECTIONS.extend([
    {'indices': (start, end), 'offset': 33, 'color': 'blue', 'lw': 1.5}
    for (start, end) in HAND_CONNECTIONS
])
# Ná»‘i cá»• tay (Wrist) cá»§a ThÃ¢n (Ä‘iá»ƒm 15) vá»›i cá»• tay Tay TrÃ¡i (Ä‘iá»ƒm 0)
ALL_CONNECTIONS.append({'indices': (15, 0), 'offset': (0, 33), 'color': 'blue', 'lw': 2})


# 3. Tay Pháº£i (Indices 54-74)
ALL_CONNECTIONS.extend([
    {'indices': (start, end), 'offset': 54, 'color': 'green', 'lw': 1.5}
    for (start, end) in HAND_CONNECTIONS
])
# Ná»‘i cá»• tay (Wrist) cá»§a ThÃ¢n (Ä‘iá»ƒm 16) vá»›i cá»• tay Tay Pháº£i (Ä‘iá»ƒm 0)
ALL_CONNECTIONS.append({'indices': (16, 0), 'offset': (0, 54), 'color': 'green', 'lw': 2})


# 4. Miá»‡ng (Indices 75-94)
ALL_CONNECTIONS.extend([
    {'indices': (start, end), 'offset': 75, 'color': 'red', 'lw': 1}
    for (start, end) in MOUTH_CONNECTIONS_20
])


def load_and_prepare_pose(pose_214):
    """
    TÃ¡ch pose 214D thÃ nh 95 keypoints (x, y) Ä‘á»ƒ váº½
    Bao gá»“m: 75 manual (tay, thÃ¢n, máº·t) + 20 mouth (tá»« NMMs)
   
    """
    # 1. Manual keypoints (75 kps)
    manual_150 = pose_214[:, :150]
    manual_kps = manual_150.reshape(-1, 75, 2)
    
    # 2. Mouth keypoints (20 kps)
    # Vá»‹ trÃ­ mouth_flat (40D) lÃ  tá»« 174
    # (aus[17] + head[3] + gaze[4] = 24) -> 150 + 24 = 174
    mouth_40 = pose_214[:, 174:] #
    mouth_kps = mouth_40.reshape(-1, 20, 2)
    
    # 3. Káº¿t há»£p láº¡i
    # [T, 95, 2] (75 Ä‘iá»ƒm Ä‘áº§u lÃ  manual, 20 Ä‘iá»ƒm sau lÃ  miá»‡ng NMM)
    all_kps = np.concatenate([manual_kps, mouth_kps], axis=1) 
    
    return all_kps

def animate_poses(gt_path, recon_path, output_video):
    """
    Táº¡o animation so sÃ¡nh Ground Truth vÃ  Reconstructed
    """
    print(f"Äang táº£i Ground Truth: {gt_path}")
    pose_gt_214 = np.load(gt_path)
    print(f"Äang táº£i Reconstructed: {recon_path}")
    pose_recon_214 = np.load(recon_path)
    
    kps_gt = load_and_prepare_pose(pose_gt_214)
    kps_recon = load_and_prepare_pose(pose_recon_214)
    
    T = len(kps_gt) # Sá»‘ frames
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
    
    def setup_ax(ax, title):
        ax.set_title(title)
        ax.invert_yaxis()
        ax.set_aspect('equal')
        ax.set_xticks([])
        ax.set_yticks([])
        
        # Láº¥y min/max tá»« GT (chá»‰ 75 Ä‘iá»ƒm manual)
        min_vals = np.min(kps_gt[:, :75].reshape(-1, 2), axis=0)
        max_vals = np.max(kps_gt[:, :75].reshape(-1, 2), axis=0)
        padding_factor = 0.2
        padding = padding_factor * (max_vals - min_vals)
        
        # Lá»c cÃ¡c Ä‘iá»ƒm (0,0) cÃ³ thá»ƒ lÃ m há»ng min/max
        valid_kps = kps_gt[:, :75][kps_gt[:, :75].any(axis=2)]
        if valid_kps.shape[0] > 0:
             min_vals = np.min(valid_kps, axis=0)
             max_vals = np.max(valid_kps, axis=0)
             padding = padding_factor * (max_vals - min_vals)
             ax.set_xlim(min_vals[0] - padding[0], max_vals[0] + padding[0])
             ax.set_ylim(max_vals[1] + padding[1], min_vals[1] - padding[1])
        
        # Táº¡o cÃ¡c Ä‘á»‘i tÆ°á»£ng Line2D rá»—ng
        lines = []
        for item in ALL_CONNECTIONS:
            (start, end) = item['indices']
            offset = item['offset']
            line = Line2D([], [], color=item['color'], lw=item['lw'], alpha=0.8)
            ax.add_line(line)
            
            # Xá»­ lÃ½ offset Ä‘áº·c biá»‡t (ná»‘i ThÃ¢n vá»›i Tay)
            if isinstance(offset, (tuple, list)):
                start_offset = offset[0]
                end_offset = offset[1]
            else:
                start_offset = offset
                end_offset = offset
                
            lines.append({'line': line, 'start': start + start_offset, 'end': end + end_offset})
            
        # ThÃªm cÃ¡c Ä‘iá»ƒm (scatter) (váº½ táº¥t cáº£ 95 Ä‘iá»ƒm)
        scatter = ax.scatter([], [], s=2, c='black', alpha=0.4)
        lines.append({'scatter': scatter, 'num_points': 95})

        return lines # Tráº£ vá» list cÃ¡c Ä‘á»‘i tÆ°á»£ng
    
    artists1 = setup_ax(ax1, 'Ground Truth')
    artists2 = setup_ax(ax2, 'Reconstructed')
    
    fig.suptitle(f'Frame 0 / {T}')

    def update(frame):
        kps_gt_frame = kps_gt[frame]     # [95, 2]
        kps_recon_frame = kps_recon[frame] # [95, 2]
        
        all_changed_artists = []
        
        # Cáº­p nháº­t cho ax1 (GT)
        for item in artists1:
            if 'line' in item:
                idx_start = item['start']
                idx_end = item['end']
                
                # Chá»‰ váº½ náº¿u cáº£ 2 Ä‘iá»ƒm khÃ´ng pháº£i lÃ  (0,0)
                if np.all(kps_gt_frame[idx_start]) and np.all(kps_gt_frame[idx_end]):
                    item['line'].set_data(
                        [kps_gt_frame[idx_start, 0], kps_gt_frame[idx_end, 0]],
                        [kps_gt_frame[idx_start, 1], kps_gt_frame[idx_end, 1]]
                    )
                else:
                    item['line'].set_data([], []) # áº¨n Ä‘Æ°á»ng ná»‘i

                all_changed_artists.append(item['line'])
                
            elif 'scatter' in item:
                num_points = item['num_points']
                # Chá»‰ váº½ cÃ¡c Ä‘iá»ƒm khÃ´ng pháº£i (0,0)
                valid_points = kps_gt_frame[:num_points][kps_gt_frame[:num_points].any(axis=1)]
                item['scatter'].set_offsets(valid_points)
                all_changed_artists.append(item['scatter'])

        # Cáº­p nháº­t cho ax2 (Recon)
        for item in artists2:
            if 'line' in item:
                idx_start = item['start']
                idx_end = item['end']

                # Chá»‰ váº½ náº¿u cáº£ 2 Ä‘iá»ƒm khÃ´ng pháº£i lÃ  (0,0)
                if np.all(kps_recon_frame[idx_start]) and np.all(kps_recon_frame[idx_end]):
                    item['line'].set_data(
                        [kps_recon_frame[idx_start, 0], kps_recon_frame[idx_end, 0]],
                        [kps_recon_frame[idx_start, 1], kps_recon_frame[idx_end, 1]]
                    )
                else:
                    item['line'].set_data([], []) # áº¨n Ä‘Æ°á»ng ná»‘i
                
                all_changed_artists.append(item['line'])
            elif 'scatter' in item:
                num_points = item['num_points']
                # Chá»‰ váº½ cÃ¡c Ä‘iá»ƒm khÃ´ng pháº£i (0,0)
                valid_points = kps_recon_frame[:num_points][kps_recon_frame[:num_points].any(axis=1)]
                item['scatter'].set_offsets(valid_points)
                all_changed_artists.append(item['scatter'])

        fig.suptitle(f'Frame {frame} / {T}')
        
        return all_changed_artists

    print(f"Äang táº¡o animation ({T} frames)...")
    ani = animation.FuncAnimation(fig, update, frames=T, blit=True, interval=40) # 25 FPS
    
    # LÆ°u video
    ani.save(output_video, writer='ffmpeg', fps=25, dpi=150)
    print(f"\nğŸ‰ ÄÃ£ lÆ°u video: {output_video}")
    plt.close()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Trá»±c quan hÃ³a so sÃ¡nh Pose')
    parser.add_argument('--gt_path', type=str, required=True,
                        help='ÄÆ°á»ng dáº«n Ä‘áº¿n file .npy cá»§a Ground Truth (tá»« check_autoencoder.py)')
    parser.add_argument('--recon_path', type=str, required=True,
                        help='ÄÆ°á»ng dáº«n Ä‘áº¿n file .npy cá»§a Reconstructed (tá»« check_autoencoder.py)')
    parser.add_argument('--output_video', type=str, default='pose_comparison_skeleton.mp4',
                        help='TÃªn file video output (mp4)')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.gt_path):
        print(f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y {args.gt_path}")
    elif not os.path.exists(args.recon_path):
        print(f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y {args.recon_path}")
    else:
        animate_poses(args.gt_path, args.recon_path, args.output_video)